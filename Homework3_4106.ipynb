{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMscl87Xl1SLLmUYcCqyYG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sesmael/Real-Time-ML-/blob/main/Homework3_4106.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Check CUDA availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Given text sequence\n",
        "text = (\"Next character prediction is a fundamental task in the field of natural language processing (NLP) \"\n",
        "        \"that involves predicting the next character in a sequence of text based on the characters that precede it. \"\n",
        "        \"This task is essential for various applications, including text auto-completion, spell checking, \"\n",
        "        \"and even in the development of sophisticated AI models capable of generating human-like text.\")\n",
        "\n",
        "# Creating character vocabulary\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_ix = {ch: i for i, ch in enumerate(chars)}\n",
        "ix_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Function to prepare datasets\n",
        "def prepare_data(sequence_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(text) - sequence_length):\n",
        "        sequence = text[i:i + sequence_length]\n",
        "        label = text[i + sequence_length]\n",
        "        X.append([char_to_ix[char] for char in sequence])\n",
        "        y.append(char_to_ix[label])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return train_test_split(torch.tensor(X, dtype=torch.long),\n",
        "                            torch.tensor(y, dtype=torch.long),\n",
        "                            test_size=0.2, random_state=42)\n",
        "\n",
        "# RNN Model Definition\n",
        "class CharRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, model_type=\"RNN\"):\n",
        "        super(CharRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        if model_type == \"RNN\":\n",
        "            self.rnn = nn.RNN(hidden_size, hidden_size, batch_first=True)\n",
        "        elif model_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
        "        elif model_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.rnn(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "# Training function\n",
        "def train_model(model_type, sequence_length):\n",
        "    X_train, X_val, y_train, y_val = prepare_data(sequence_length)\n",
        "    model = CharRNN(len(chars), 128, len(chars), model_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(50):\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X_train.to(device))\n",
        "        loss = criterion(output, y_train.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_output = model(X_val.to(device))\n",
        "            val_loss = criterion(val_output, y_val.to(device))\n",
        "            val_accuracy = (torch.argmax(val_output, 1) == y_val.to(device)).float().mean()\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'{model_type} - Seq Length {sequence_length} | Epoch {epoch+1}: Loss {loss.item():.4f}, Val Acc {val_accuracy.item():.4f}')\n",
        "\n",
        "    exec_time = time.time() - start_time\n",
        "    return loss.item(), val_accuracy.item(), exec_time, sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Running experiments\n",
        "sequence_lengths = [10, 20, 30]\n",
        "models = [\"RNN\", \"LSTM\", \"GRU\"]\n",
        "results = []\n",
        "for seq_len in sequence_lengths:\n",
        "    for model in models:\n",
        "        loss, accuracy, exec_time, model_size = train_model(model, seq_len)\n",
        "        results.append((model, seq_len, loss, accuracy, exec_time, model_size))\n",
        "\n",
        "# Displaying results\n",
        "import pandas as pd\n",
        "\n",
        "# Convert results to a DataFrame\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Sequence Length\", \"Training Loss\", \"Validation Accuracy\", \"Execution Time (s)\", \"Model Size\"])\n",
        "\n",
        "# Print results as a table\n",
        "print(results_df)\n",
        "\n",
        "# Save results to a CSV file (optional)\n",
        "results_df.to_csv(\"rnn_lstm_gru_comparison.csv\", index=False)\n",
        "\n",
        "print(\"Results saved to 'rnn_lstm_gru_comparison.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMSzeHfteDs0",
        "outputId": "f8cdf892-201a-4ca5-f26b-9caa9b621024"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RNN - Seq Length 10 | Epoch 10: Loss 1.6465, Val Acc 0.2597\n",
            "RNN - Seq Length 10 | Epoch 20: Loss 0.7395, Val Acc 0.2857\n",
            "RNN - Seq Length 10 | Epoch 30: Loss 0.2374, Val Acc 0.2468\n",
            "RNN - Seq Length 10 | Epoch 40: Loss 0.0659, Val Acc 0.2597\n",
            "RNN - Seq Length 10 | Epoch 50: Loss 0.0233, Val Acc 0.2727\n",
            "LSTM - Seq Length 10 | Epoch 10: Loss 2.1638, Val Acc 0.2078\n",
            "LSTM - Seq Length 10 | Epoch 20: Loss 1.2374, Val Acc 0.2468\n",
            "LSTM - Seq Length 10 | Epoch 30: Loss 0.4831, Val Acc 0.2468\n",
            "LSTM - Seq Length 10 | Epoch 40: Loss 0.1209, Val Acc 0.2338\n",
            "LSTM - Seq Length 10 | Epoch 50: Loss 0.0349, Val Acc 0.2208\n",
            "GRU - Seq Length 10 | Epoch 10: Loss 1.9211, Val Acc 0.2208\n",
            "GRU - Seq Length 10 | Epoch 20: Loss 0.9489, Val Acc 0.2208\n",
            "GRU - Seq Length 10 | Epoch 30: Loss 0.2961, Val Acc 0.2727\n",
            "GRU - Seq Length 10 | Epoch 40: Loss 0.0710, Val Acc 0.2727\n",
            "GRU - Seq Length 10 | Epoch 50: Loss 0.0225, Val Acc 0.2597\n",
            "RNN - Seq Length 20 | Epoch 10: Loss 1.6347, Val Acc 0.2000\n",
            "RNN - Seq Length 20 | Epoch 20: Loss 0.7194, Val Acc 0.2267\n",
            "RNN - Seq Length 20 | Epoch 30: Loss 0.2311, Val Acc 0.2533\n",
            "RNN - Seq Length 20 | Epoch 40: Loss 0.0703, Val Acc 0.2400\n",
            "RNN - Seq Length 20 | Epoch 50: Loss 0.0270, Val Acc 0.2533\n",
            "LSTM - Seq Length 20 | Epoch 10: Loss 2.1540, Val Acc 0.2267\n",
            "LSTM - Seq Length 20 | Epoch 20: Loss 1.1706, Val Acc 0.2133\n",
            "LSTM - Seq Length 20 | Epoch 30: Loss 0.4253, Val Acc 0.2933\n",
            "LSTM - Seq Length 20 | Epoch 40: Loss 0.1153, Val Acc 0.2667\n",
            "LSTM - Seq Length 20 | Epoch 50: Loss 0.0363, Val Acc 0.2267\n",
            "GRU - Seq Length 20 | Epoch 10: Loss 1.9082, Val Acc 0.2133\n",
            "GRU - Seq Length 20 | Epoch 20: Loss 0.9572, Val Acc 0.2400\n",
            "GRU - Seq Length 20 | Epoch 30: Loss 0.3118, Val Acc 0.2667\n",
            "GRU - Seq Length 20 | Epoch 40: Loss 0.0888, Val Acc 0.2533\n",
            "GRU - Seq Length 20 | Epoch 50: Loss 0.0306, Val Acc 0.2133\n",
            "RNN - Seq Length 30 | Epoch 10: Loss 1.6130, Val Acc 0.2466\n",
            "RNN - Seq Length 30 | Epoch 20: Loss 0.7028, Val Acc 0.2055\n",
            "RNN - Seq Length 30 | Epoch 30: Loss 0.2111, Val Acc 0.2603\n",
            "RNN - Seq Length 30 | Epoch 40: Loss 0.0615, Val Acc 0.2466\n",
            "RNN - Seq Length 30 | Epoch 50: Loss 0.0217, Val Acc 0.2192\n",
            "LSTM - Seq Length 30 | Epoch 10: Loss 2.1423, Val Acc 0.1644\n",
            "LSTM - Seq Length 30 | Epoch 20: Loss 1.2113, Val Acc 0.1918\n",
            "LSTM - Seq Length 30 | Epoch 30: Loss 0.5207, Val Acc 0.2055\n",
            "LSTM - Seq Length 30 | Epoch 40: Loss 0.1612, Val Acc 0.1918\n",
            "LSTM - Seq Length 30 | Epoch 50: Loss 0.0541, Val Acc 0.1918\n",
            "GRU - Seq Length 30 | Epoch 10: Loss 1.9458, Val Acc 0.2466\n",
            "GRU - Seq Length 30 | Epoch 20: Loss 0.9476, Val Acc 0.2466\n",
            "GRU - Seq Length 30 | Epoch 30: Loss 0.3142, Val Acc 0.3014\n",
            "GRU - Seq Length 30 | Epoch 40: Loss 0.0888, Val Acc 0.2877\n",
            "GRU - Seq Length 30 | Epoch 50: Loss 0.0324, Val Acc 0.3014\n",
            "  Model  Sequence Length  Training Loss  Validation Accuracy  \\\n",
            "0   RNN               10       0.023309             0.272727   \n",
            "1  LSTM               10       0.034863             0.220779   \n",
            "2   GRU               10       0.022547             0.259740   \n",
            "3   RNN               20       0.027022             0.253333   \n",
            "4  LSTM               20       0.036310             0.226667   \n",
            "5   GRU               20       0.030578             0.213333   \n",
            "6   RNN               30       0.021739             0.219178   \n",
            "7  LSTM               30       0.054137             0.191781   \n",
            "8   GRU               30       0.032421             0.301370   \n",
            "\n",
            "   Execution Time (s)  Model Size  \n",
            "0            0.200876       41762  \n",
            "1            0.275173      140834  \n",
            "2            0.238269      107810  \n",
            "3            0.225840       41762  \n",
            "4            0.294459      140834  \n",
            "5            0.261143      107810  \n",
            "6            0.218553       41762  \n",
            "7            0.315963      140834  \n",
            "8            0.275418      107810  \n",
            "Results saved to 'rnn_lstm_gru_comparison.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZ_n_cFe4i08",
        "outputId": "fc768073-83c1-4597-ddf0-c0a7e767ac2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "LSTM - Seq Length 20 | Epoch 10: Loss 9955.0330, Val Acc 0.5535\n",
            "LSTM - Seq Length 20 | Epoch 20: Loss 10480.6142, Val Acc 0.5328\n",
            "LSTM - Seq Length 20 | Epoch 30: Loss 11838.6115, Val Acc 0.4921\n",
            "GRU - Seq Length 20 | Epoch 10: Loss 15247.3753, Val Acc 0.3660\n",
            "GRU - Seq Length 20 | Epoch 20: Loss 14008.0638, Val Acc 0.4125\n",
            "GRU - Seq Length 20 | Epoch 30: Loss 13157.8531, Val Acc 0.4477\n",
            "LSTM - Seq Length 30 | Epoch 10: Loss 9778.4563, Val Acc 0.5598\n",
            "LSTM - Seq Length 30 | Epoch 20: Loss 9960.5545, Val Acc 0.5531\n",
            "LSTM - Seq Length 30 | Epoch 30: Loss 10331.1304, Val Acc 0.5394\n",
            "GRU - Seq Length 30 | Epoch 10: Loss 14822.9504, Val Acc 0.3823\n",
            "GRU - Seq Length 30 | Epoch 20: Loss 14651.3563, Val Acc 0.3889\n",
            "GRU - Seq Length 30 | Epoch 30: Loss 12830.0405, Val Acc 0.4397\n",
            "  Model  Sequence Length  Training Loss  Validation Accuracy  \\\n",
            "0  LSTM               20   11838.611453             0.492099   \n",
            "1   GRU               20   13157.853111             0.447715   \n",
            "2  LSTM               30   10331.130356             0.539446   \n",
            "3   GRU               30   12830.040512             0.439686   \n",
            "\n",
            "   Execution Time (s)  Model Size  \n",
            "0         1778.384405     1086017  \n",
            "1         1449.149889      822849  \n",
            "2         1773.289531     1086017  \n",
            "3         1449.640286      822849  \n",
            "Results saved to 'lstm_gru_comparison.csv'\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import requests\n",
        "\n",
        "# Check CUDA availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Step 1: Download the dataset\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text  # This is the entire text data\n",
        "\n",
        "# Step 2: Prepare the dataset\n",
        "sequence_length = 20\n",
        "# Create a character mapping to integers\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encode the text into integers\n",
        "encoded_text = [char_to_int[ch] for ch in text]\n",
        "\n",
        "# Create sequences and targets\n",
        "sequences = []\n",
        "targets = []\n",
        "for i in range(0, len(encoded_text) - sequence_length):\n",
        "    seq = encoded_text[i:i+sequence_length]\n",
        "    target = encoded_text[i+sequence_length]\n",
        "    sequences.append(seq)\n",
        "    targets.append(target)\n",
        "\n",
        "# Convert lists to PyTorch tensors\n",
        "sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Step 3: Create a dataset class\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences.to(device)\n",
        "        self.targets = targets.to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "# Instantiate the dataset\n",
        "dataset = CharDataset(sequences, targets)\n",
        "\n",
        "# Step 4: Create data loaders\n",
        "batch_size = 128\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size)\n",
        "\n",
        "# Model Definition\n",
        "class CharLSTMGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, model_type=\"LSTM\"):\n",
        "        super(CharLSTMGRU, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size).to(device)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        if model_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True).to(device)\n",
        "        elif model_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True).to(device)\n",
        "        self.fc = nn.Linear(hidden_size, output_size).to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(device)\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.rnn(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "# Training function\n",
        "def train_model(model_type, sequence_length):\n",
        "    model = CharLSTMGRU(len(chars), 256, len(chars), 2, model_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.003)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(30):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X_val, y_val in test_loader:\n",
        "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "                val_output = model(X_val)\n",
        "                predicted = torch.argmax(val_output, 1)\n",
        "                correct += (predicted == y_val).sum().item()\n",
        "                total += y_val.size(0)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f'{model_type} - Seq Length {sequence_length} | Epoch {epoch+1}: Loss {total_loss:.4f}, Val Acc {val_accuracy:.4f}')\n",
        "\n",
        "    exec_time = time.time() - start_time\n",
        "    return total_loss, val_accuracy, exec_time, sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Running experiments\n",
        "sequence_lengths = [20, 30]\n",
        "results = []\n",
        "for seq_len in sequence_lengths:\n",
        "    for model in [\"LSTM\", \"GRU\"]:\n",
        "        loss, accuracy, exec_time, model_size = train_model(model, seq_len)\n",
        "        results.append((model, seq_len, loss, accuracy, exec_time, model_size))\n",
        "\n",
        "# Display results\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Sequence Length\", \"Training Loss\", \"Validation Accuracy\", \"Execution Time (s)\", \"Model Size\"])\n",
        "print(results_df)\n",
        "results_df.to_csv(\"lstm_gru_comparison.csv\", index=False)\n",
        "print(\"Results saved to 'lstm_gru_comparison.csv'\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized Google Colab LSTM vs GRU Training (20 Epochs)\n",
        "\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "# Check CUDA availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Step 1: Download the dataset\n",
        "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
        "response = requests.get(url)\n",
        "text = response.text\n",
        "\n",
        "# Step 2: Prepare the dataset\n",
        "sequence_length = 50\n",
        "chars = sorted(list(set(text)))\n",
        "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
        "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
        "\n",
        "# Encode the text into integers\n",
        "encoded_text = np.array([char_to_int[ch] for ch in text], dtype=np.int32)\n",
        "\n",
        "# Create sequences and targets using NumPy\n",
        "num_samples = len(encoded_text) - sequence_length\n",
        "sequences = np.zeros((num_samples, sequence_length), dtype=np.int32)\n",
        "targets = np.zeros(num_samples, dtype=np.int32)\n",
        "\n",
        "for i in range(num_samples):\n",
        "    sequences[i] = encoded_text[i:i + sequence_length]\n",
        "    targets[i] = encoded_text[i + sequence_length]\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "sequences = torch.tensor(sequences, dtype=torch.long)\n",
        "targets = torch.tensor(targets, dtype=torch.long)\n",
        "\n",
        "# Step 3: Create Dataset Class\n",
        "class CharDataset(Dataset):\n",
        "    def __init__(self, sequences, targets):\n",
        "        self.sequences = sequences\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.sequences[index], self.targets[index]\n",
        "\n",
        "dataset = CharDataset(sequences, targets)\n",
        "del sequences, targets, text, encoded_text  # Free memory\n",
        "\n",
        "# Step 4: Create DataLoaders\n",
        "batch_size = 64\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=batch_size, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "# Model Definition\n",
        "class CharLSTMGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_layers, model_type=\"LSTM\"):\n",
        "        super(CharLSTMGRU, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        if model_type == \"LSTM\":\n",
        "            self.rnn = nn.LSTM(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        elif model_type == \"GRU\":\n",
        "            self.rnn = nn.GRU(hidden_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.rnn(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output\n",
        "\n",
        "# Training function (Train for 20 Epochs)\n",
        "def train_model(model_type):\n",
        "    model = CharLSTMGRU(len(chars), 128, len(chars), 1, model_type).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.5)  # Adjusted for 20 epochs\n",
        "\n",
        "    start_time = time.time()\n",
        "    epoch_results = []\n",
        "\n",
        "    for epoch in range(20):  # Train for 20 epochs\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            output = model(X_batch)\n",
        "            loss = criterion(output, y_batch)\n",
        "\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        correct, total = 0, 0\n",
        "        with torch.no_grad():\n",
        "            for X_val, y_val in test_loader:\n",
        "                X_val, y_val = X_val.to(device), y_val.to(device)\n",
        "                val_output = model(X_val)\n",
        "                predicted = torch.argmax(val_output, 1)\n",
        "                correct += (predicted == y_val).sum().item()\n",
        "                total += y_val.size(0)\n",
        "        val_accuracy = correct / total\n",
        "\n",
        "        # Print every epoch result\n",
        "        print(f'{model_type} | Epoch {epoch+1}: Loss {total_loss:.4f}, Val Acc {val_accuracy:.4f}')\n",
        "        epoch_results.append((epoch+1, model_type, total_loss, val_accuracy))\n",
        "\n",
        "    exec_time = time.time() - start_time\n",
        "    return epoch_results, exec_time, sum(p.numel() for p in model.parameters())\n",
        "\n",
        "# Running experiments\n",
        "results = []\n",
        "epoch_logs = []\n",
        "\n",
        "for model in [\"LSTM\", \"GRU\"]:\n",
        "    epoch_results, exec_time, model_size = train_model(model)\n",
        "    results.append((model, sequence_length, exec_time, model_size))\n",
        "    epoch_logs.extend(epoch_results)\n",
        "\n",
        "# Save and display epoch-wise results\n",
        "epoch_df = pd.DataFrame(epoch_logs, columns=[\"Epoch\", \"Model\", \"Training Loss\", \"Validation Accuracy\"])\n",
        "epoch_df.to_csv(\"epoch_logs.csv\", index=False)\n",
        "files.download(\"epoch_logs.csv\")\n",
        "\n",
        "# Save and display model-wise results\n",
        "results_df = pd.DataFrame(results, columns=[\"Model\", \"Sequence Length\", \"Execution Time (s)\", \"Model Size\"])\n",
        "results_df.to_csv(\"lstm_gru_comparison.csv\", index=False)\n",
        "files.download(\"lstm_gru_comparison.csv\")\n",
        "\n",
        "# Print final results\n",
        "print(results_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        },
        "id": "lEQUUtDWf7f3",
        "outputId": "4ce730c9-d56c-4d21-8814-77f28d02b1c1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "LSTM | Epoch 1: Loss 24807.0632, Val Acc 0.4987\n",
            "LSTM | Epoch 2: Loss 22972.0424, Val Acc 0.5096\n",
            "LSTM | Epoch 3: Loss 22690.8442, Val Acc 0.5125\n",
            "LSTM | Epoch 4: Loss 22640.9099, Val Acc 0.5114\n",
            "LSTM | Epoch 5: Loss 22692.5390, Val Acc 0.5153\n",
            "LSTM | Epoch 6: Loss 22738.0605, Val Acc 0.5110\n",
            "LSTM | Epoch 7: Loss 22850.8748, Val Acc 0.5078\n",
            "LSTM | Epoch 8: Loss 21727.7429, Val Acc 0.5334\n",
            "LSTM | Epoch 9: Loss 21296.8081, Val Acc 0.5370\n",
            "LSTM | Epoch 10: Loss 21123.7980, Val Acc 0.5405\n",
            "LSTM | Epoch 11: Loss 21000.2590, Val Acc 0.5428\n",
            "LSTM | Epoch 12: Loss 20914.7041, Val Acc 0.5415\n",
            "LSTM | Epoch 13: Loss 20834.1538, Val Acc 0.5438\n",
            "LSTM | Epoch 14: Loss 20787.0868, Val Acc 0.5423\n",
            "LSTM | Epoch 15: Loss 20227.3076, Val Acc 0.5552\n",
            "LSTM | Epoch 16: Loss 20025.8245, Val Acc 0.5584\n",
            "LSTM | Epoch 17: Loss 19917.1863, Val Acc 0.5587\n",
            "LSTM | Epoch 18: Loss 19839.5604, Val Acc 0.5603\n",
            "LSTM | Epoch 19: Loss 19787.8821, Val Acc 0.5593\n",
            "LSTM | Epoch 20: Loss 19729.9911, Val Acc 0.5590\n",
            "GRU | Epoch 1: Loss 27030.0689, Val Acc 0.4510\n",
            "GRU | Epoch 2: Loss 26372.2197, Val Acc 0.4539\n",
            "GRU | Epoch 3: Loss 26400.8765, Val Acc 0.4510\n",
            "GRU | Epoch 4: Loss 26489.5780, Val Acc 0.4498\n",
            "GRU | Epoch 5: Loss 26513.9661, Val Acc 0.4506\n",
            "GRU | Epoch 6: Loss 26663.0785, Val Acc 0.4432\n",
            "GRU | Epoch 7: Loss 26747.7787, Val Acc 0.4348\n",
            "GRU | Epoch 8: Loss 25056.4246, Val Acc 0.4829\n",
            "GRU | Epoch 9: Loss 24646.5937, Val Acc 0.4866\n",
            "GRU | Epoch 10: Loss 24381.2785, Val Acc 0.4862\n",
            "GRU | Epoch 11: Loss 24203.5873, Val Acc 0.4892\n",
            "GRU | Epoch 12: Loss 24080.1599, Val Acc 0.4970\n",
            "GRU | Epoch 13: Loss 23975.9899, Val Acc 0.4985\n",
            "GRU | Epoch 14: Loss 23923.3523, Val Acc 0.4947\n",
            "GRU | Epoch 15: Loss 23091.4873, Val Acc 0.5121\n",
            "GRU | Epoch 16: Loss 22863.6261, Val Acc 0.5116\n",
            "GRU | Epoch 17: Loss 22733.0909, Val Acc 0.5159\n",
            "GRU | Epoch 18: Loss 22650.7349, Val Acc 0.5190\n",
            "GRU | Epoch 19: Loss 22580.1212, Val Acc 0.5175\n",
            "GRU | Epoch 20: Loss 22496.8850, Val Acc 0.5194\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0a6f967f-db6e-4df3-a9b6-2625010cb090\", \"epoch_logs.csv\", 1836)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7d86a8df-d4c1-4997-be9b-fe647e6836b2\", \"lstm_gru_comparison.csv\", 119)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Model  Sequence Length  Execution Time (s)  Model Size\n",
            "0  LSTM               50         1084.554183      148801\n",
            "1   GRU               50         1059.254674      115777\n"
          ]
        }
      ]
    }
  ]
}